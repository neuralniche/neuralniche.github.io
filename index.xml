<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>neural niche</title>
    <link>http://neuralniche.com/</link>
    <description>Recent content on neural niche</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <copyright>ðŸ˜ˆ</copyright>
    <lastBuildDate>Thu, 10 Sep 2015 12:02:41 -0700</lastBuildDate>
    <atom:link href="http://neuralniche.com/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>using generative neural nets in keras to create â€˜on-the-flyâ€™ dialogue</title>
      <link>http://neuralniche.com/post/tutorial/</link>
      <pubDate>Thu, 10 Sep 2015 12:02:41 -0700</pubDate>
      
      <guid>http://neuralniche.com/post/tutorial/</guid>
      <description>

&lt;h3 id=&#34;introduction:94d9a081cd1256334373c8ca6fb6276c&#34;&gt;introduction:&lt;/h3&gt;

&lt;p&gt;there&amp;rsquo;s been a few cool things done with generative neural nets so far but to my knowledge, very few generative neural nets have found a useful application in any business realm (or has been posted about).  this is by no means the best use or the most interesting but, i think it is an incredibly interesting idea and is a potential starting point for generative neural nets to be utilized in a way that is incredibly beneficial for training or as a useful tool.&lt;/p&gt;

&lt;p&gt;there&amp;rsquo;s  a lot of potential for this and other similar sorts of technologies and i&amp;rsquo;d love to work on or collaborate with others on something.  if you are interested please contact me at the email listed on the bottom of this post.&lt;/p&gt;

&lt;h2 id=&#34;let-s-start:94d9a081cd1256334373c8ca6fb6276c&#34;&gt;let&amp;rsquo;s start&lt;/h2&gt;

&lt;p&gt;my initial idea started with the idea that the tons and tons of dialogue that youtube videos have already (closed captioning) which is already a massive dataset and could potentially be used to train a lot of different machine learning models.  i think it also has the ability to resemble human dialogue somewhat (and shows promise over a lot of similar attempts at NLP concepts i have experimented with).  it may not be &lt;em&gt;perfect&lt;/em&gt;, but it does seem to carry many of the interesting inflections and peculiarities of human speech that written word does not always capture.&lt;/p&gt;

&lt;p&gt;the training set to create this model is just a collection of youtube vids that deal with sales or call oriented dialogue, for instance heres a couple of the videos i used:&lt;/p&gt;

&lt;p&gt;&lt;a href=&#34;http://www.youtube.com/watch?v=3fbmf2IAEVM&#34;&gt;&lt;img src=&#34;http://img.youtube.com/vi/3fbmf2IAEVM/0.jpg&#34; alt=&#34;example 1&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;http://www.youtube.com/watch?v=4ostqJD3Psc&#34;&gt;&lt;img src=&#34;http://img.youtube.com/vi/4ostqJD3Psc/0.jpg&#34; alt=&#34;example 1&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;there&amp;rsquo;s not a particular reason i used any of these videos other than they are very long, may have phone dialogue, and have subtitles/closed captions already.  i tried to find vids that seemed like the captions were somewhat accurate but this was very haphazard and i&amp;rsquo;m sure it&amp;rsquo;s effect on the training set is noticeable.  i won&amp;rsquo;t claim to have watched these vids or to even know what they are discussing, but that&amp;rsquo;s kind of why i think this technology is interesting.  also the cc are not perfect and it&amp;rsquo;s easy to see they have a lot of mistakes, if you have a suggestion for how to fix this, please let me know!&lt;/p&gt;

&lt;p&gt;from here, all that is necessary now is to collect enough videos for a string length of greater than ~500k.&lt;/p&gt;

&lt;p&gt;i have a python script that uses youtube-dl and pysrt to grab the subtitles/closed captions.  you don&amp;rsquo;t need pysrt since the subtitles are very standardized but it&amp;rsquo;s useful if you wish to venture to stuff outside of youtube.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import youtube_dl, pysrt
import numpy as np

class audio_source(object):
    def __init__(self, url):
        self.url = url
        self.ydl_opts = {
            &#39;subtitles&#39;: &#39;en&#39;,
            &#39;writesubtitles&#39;: True,
            &#39;writeautomaticsub&#39;: True}

        self.subtitlesavailable = self.are_subs_available()

        if self.subtitlesavailable:
            self.grab_auto_subs()

    def are_subs_available(self):
        with youtube_dl.YoutubeDL(self.ydl_opts) as ydl:
            subs = ydl.extract_info(self.url, download=False)
        if subs[&#39;requested_subtitles&#39;]:
            self.title = subs[&#39;title&#39;]
            self.subs_url = subs[&#39;requested_subtitles&#39;][&#39;en&#39;][&#39;url&#39;]
            return True
        else:
            return False

    def grab_auto_subs(self):
        &amp;quot;&amp;quot;&amp;quot;
        grab&#39;s subs or cc depending on whats available,
        think it grabs both if subtitles are available
        issue with ydl_opts but doesn&#39;t bother me
        &amp;quot;&amp;quot;&amp;quot;
        try:
            urllib.request.urlretrieve(
                self.subs_url, &#39;youtube-dl-texts/&#39; + self.title + &#39;.srt&#39;)
            print(&amp;quot;subtitles saved directly from youtube\n&amp;quot;)
            text = pysrt.open(&#39;youtube-dl-texts/&#39; + self.title + &#39;.srt&#39;)
            self.text = text.text.replace(&#39;\n&#39;, &#39; &#39;)
        except IOError:
            print(&amp;quot;\n *** saving sub&#39;s didn&#39;t work *** \n&amp;quot;)

with open(&#39;other/url_list&#39;,&#39;r&#39;) as datafile:
    url_list = datafile.read().splitlines()

total_text = []

for u in url_list:
    try:
        total_text.append(audio_source(url=u).text)
    except AttributeError:
        pass
total_text = &#39; &#39;.join(total_text).lower()

print(len(total_text))

&amp;gt;&amp;gt;&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;training-the-generative-neural-net:94d9a081cd1256334373c8ca6fb6276c&#34;&gt;training the generative neural net&lt;/h2&gt;

&lt;p&gt;at this point you have a mass of text that if you read it, probably looks pretty incoherent and useless (also i&amp;rsquo;m not creating a separation between texts like many other text&amp;rsquo;s have and would probably be very useful in disseminating when a conversation should be ended etc).  the great thing is that &lt;em&gt;hopefully&lt;/em&gt; there is enough data to create an end result for the time being and the errors will regress to the mean so to speak (with long enough text&amp;rsquo;s there seems to be truth to this).&lt;/p&gt;

&lt;p&gt;here&amp;rsquo;s an example of some of the last 260 chars of the dialogue i have from slightly less than 1 MB worth of text from videos:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;print(total_text[-260:])
&amp;gt;&amp;gt;&amp;gt;&#39;more information about those meetings and travel make sure to fax it to this number at the bottom and are you into the grand prize drawing weeks stay at intercontinental resort Tahiti be sure to fax in that form you all right thank you feel you have a great day&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;to train the model we first need to do a bit of preprocessing since the generative neural net uses sequential data character by character (well in &lt;em&gt;steps&lt;/em&gt;, but character by character for each step (a fair amount of this is from the &lt;a href=&#34;https://github.com/fchollet/keras/blob/master/examples/lstm_text_generation.py&#34;&gt;keras LSTM generating example&lt;/a&gt;)&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;chars = set(total_text)

char_indices = dict((c, i) for i, c in enumerate(chars))
indices_char = dict((i, c) for i, c in enumerate(chars))


maxlen = 20
step = 1
sentences = []
next_chars = []
for i in range(0, len(total_text) - maxlen, step):
    sentences.append(total_text[i: i + maxlen])
    next_chars.append(total_text[i + maxlen])
print(&#39;nb sequences:&#39;, len(sentences))



X = np.zeros((len(sentences), maxlen, len(chars)), dtype=np.bool)
y = np.zeros((len(sentences), len(chars)), dtype=np.bool)
for i, sentence in enumerate(sentences):
    for t, char in enumerate(sentence):
        X[i, t, char_indices[char]] = 1
    y[i, char_indices[next_chars[i]]] = 1
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;lstm-training:94d9a081cd1256334373c8ca6fb6276c&#34;&gt;LSTM training&lt;/h4&gt;

&lt;p&gt;for a NN library, i am using keras for a few reasons but it is so far my favorite python NN library due to how modular and easy to understand it is (and the &lt;a href=&#34;https://github.com/fchollet/&#34;&gt;creator&lt;/a&gt; and contributors seem incredibly smart)
using keras and a LSTM architecture is the easiest to show but there&amp;rsquo;s tons of ways to improve this as well (different layers, cascading architectures, etc). play around and let me know if you find something superior!&lt;/p&gt;

&lt;p&gt;one of the better models i found:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;from keras.models import Sequential
from keras.layers.core import Dense, Activation, Dropout
from keras.layers.recurrent import LSTM


model = Sequential()
# input -&amp;gt; layer 1
model.add(LSTM(len(chars), 512, return_sequences=True))
model.add(Dropout(0.20))
# use 20% dropout on all LSTM layers: http://arxiv.org/abs/1312.4569

# 1.5 testing
model.add(LSTM(512, 512, return_sequences=True))
model.add(Dropout(0.20))
# layer 2
model.add(LSTM(512, 256, return_sequences=True))
model.add(Dropout(0.20))
# layer 3
model.add(LSTM(256, 256, return_sequences=False))
model.add(Dropout(0.20))
# layer 4 -&amp;gt; output
model.add(Dense(256, len(chars)))
model.add(Activation(&#39;softmax&#39;))

# compile or load weights then compile depending
model.compile(loss=&#39;categorical_crossentropy&#39;, optimizer=&#39;rmsprop&#39;)

model.fit(X,y,nb_epoch=50)

&amp;gt;&amp;gt;&amp;gt; Epoch 0
&amp;gt;&amp;gt;&amp;gt; 7744/285648 [&amp;gt;.............................] - ETA: 4717s - loss: 3.0232
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;this will probably take quite awhile using a personal computer even with a GPU.  From my experimentation it is optimal to get a loss to around .8 - .4 which takes around 40-50 epoch&amp;rsquo;s&lt;/p&gt;

&lt;p&gt;at this point, a model is trained and we are ready to generate some recommended dialogue&lt;/p&gt;

&lt;h2 id=&#34;generate-some-text:94d9a081cd1256334373c8ca6fb6276c&#34;&gt;generate some text&lt;/h2&gt;

&lt;p&gt;the final part of this is being able to speak something to your computer (or potentially, computer would listen to what you or someone else is saying in some app or extension) and from there get the speech into text form to generate a suggestion of what to follow that sentence with.&lt;/p&gt;

&lt;p&gt;there&amp;rsquo;s a few ways to do this but the easiest is to register and get an API key for google speech to text, and install some libraries to be able to use the &lt;a href=&#34;https://pypi.python.org/pypi/SpeechRecognition/&#34;&gt;python speech recognition module&lt;/a&gt;
use a personal key in the Recognizer since otherwise it won&amp;rsquo;t work for other&amp;rsquo;s using the module once it hit&amp;rsquo;s 50 queries.  you need to subscribe to a mailing list and then &lt;a href=&#34;http://www.chromium.org/developers/how-tos/api-keys&#34;&gt;enable the api but it takes about 2 minutes.&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;you can incorporate whatever was spoken into the model as well, but that&amp;rsquo;s for a later date.  right now, all i will do is set it up so you speak to it for a moment and then it generates some text and prints that out.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;import speech_recognition as sr

recognizer = sr.Recognizer(key=myKey)

def speech2text(r=recognizer):

    # speak to microphone, use google api, return text
    input(&#39;press enter then speak: \n&#39;+&#39;------&#39;*5)
    with sr.Microphone() as source:
        audio = r.listen(source)
        try:
            print(&#39;\nprocessing...\n&#39;)
            return r.recognize(audio).lower()
        except LookupError:
            pass

def gentext():

    seed_text = speech2text()
    generated = &#39;&#39; + seed_text
    print(&#39;------&#39;*5+&#39;\nyou said: \n&#39;+&#39;&amp;quot;&#39; + seed_text +&#39;&amp;quot;&#39;)


    print(&#39;------&#39;*5+&#39;\n generating...\n&#39;+ &#39;------&#39;*5)
    for iteration in range(50):
        # create x vector from seed to predict off of
        x = np.zeros((1, len(seed_text), len(chars)))
        for t, char in enumerate(seed_text):
            x[0, t, char_indices[char]] = 1.

        preds = model.predict(x, verbose=0)[0]
        next_index = np.argmax(preds)
        next_char = indices_char[next_index]

        generated += next_char
        seed_text = seed_text[1:] + next_char
    print(&#39;\n\nfollow up with: &#39; + generated)

&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;here&amp;rsquo;s one of the best single example&amp;rsquo;s i&amp;rsquo;ve found with this model and have gotten a lot different results from a variety of attempts and architecture&amp;rsquo;s and planning on posting more if it would be useful (or can post the exact architecture and model weights which keras can then load):&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gentext()

press enter then speak:
------------------------------

processing...

------------------------------
you said:
&amp;quot;i would like to talk to you about a house i saw that you had for sale&amp;quot;
------------------------------
 generating...
------------------------------

follow up with:
i would like to talk to you about a house i saw that you had for sale tell me what was its price though and i can reall
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;note:94d9a081cd1256334373c8ca6fb6276c&#34;&gt;note:&lt;/h4&gt;

&lt;p&gt;in terms of training the model, training/predicting with a GPU vs CPU is about 3-4x faster on my 2013 macbook pro&lt;/p&gt;

&lt;h2 id=&#34;conclusion:94d9a081cd1256334373c8ca6fb6276c&#34;&gt;conclusion&lt;/h2&gt;

&lt;p&gt;with something like this, it&amp;rsquo;s very easy to see how you could splice in audio from a phone call or text chat that this would carry over very well to.  given the right data set&amp;rsquo;s theres tons of potential uses.  along with this, there&amp;rsquo;s also ways to stack and blend models together that provide different and separate different dialogue/differentiate people within dialogue.&lt;/p&gt;

&lt;p&gt;this all came about because after the yc fellowship rejection, i thought i may as well post this since i personally think it has a ton of potential.  if you are interested in hearing more about this, or hearing more about this type of stuff, contact me at the email posted below or signup for a newsletter.&lt;/p&gt;

&lt;p&gt;&lt;br&gt;
&lt;a href=&#34;mailto:graham.annett@gmail.com&#34;&gt;contact me&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;link href=&#34;//cdn-images.mailchimp.com/embedcode/slim-081711.css&#34; rel=&#34;stylesheet&#34; type=&#34;text/css&#34;&gt;
&lt;style type=&#34;text/css&#34;&gt;
    #mc_embed_signup{background:#fff; clear:left; font:14px Helvetica,Arial,sans-serif; }
    /* Add your own MailChimp form style overrides in your site stylesheet or in this style block.
       We recommend moving this block and the preceding CSS link to the HEAD of your HTML file. */
&lt;/style&gt;
&lt;div id=&#34;mc_embed_signup&#34;&gt;
&lt;form action=&#34;//neuralniche.us11.list-manage.com/subscribe/post?u=7f3e6432894032f97ce9da591&amp;amp;id=a86a7392be&#34; method=&#34;post&#34; id=&#34;mc-embedded-subscribe-form&#34; name=&#34;mc-embedded-subscribe-form&#34; class=&#34;validate&#34; target=&#34;_blank&#34; novalidate&gt;
&lt;div id=&#34;mc_embed_signup_scroll&#34;&gt;
&lt;label for=&#34;mce-EMAIL&#34;&gt;Subscribe to our mailing list&lt;/label&gt;
&lt;input type=&#34;email&#34; value=&#34;&#34; name=&#34;EMAIL&#34; class=&#34;email&#34; id=&#34;mce-EMAIL&#34; placeholder=&#34;email address&#34; required&gt;
&lt;div style=&#34;position: absolute; left: -5000px;&#34;&gt;&lt;input type=&#34;text&#34; name=&#34;b_7f3e6432894032f97ce9da591_a86a7392be&#34; tabindex=&#34;-1&#34; value=&#34;&#34;&gt;&lt;/div&gt;
&lt;div class=&#34;clear&#34;&gt;&lt;input type=&#34;submit&#34; value=&#34;Subscribe&#34; name=&#34;subscribe&#34; id=&#34;mc-embedded-subscribe&#34; class=&#34;button&#34;&gt;&lt;/div&gt;
&lt;/div&gt;
&lt;/form&gt;
&lt;/div&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>hey!</title>
      <link>http://neuralniche.com/post/first/</link>
      <pubDate>Wed, 19 Aug 2015 12:02:41 -0700</pubDate>
      
      <guid>http://neuralniche.com/post/first/</guid>
      <description>&lt;p&gt;&lt;br /&gt;
will have:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;example&lt;/li&gt;
&lt;li&gt;example code&lt;/li&gt;
&lt;li&gt;ipython notebook&lt;/li&gt;
&lt;/ul&gt;

&lt;div class=&#34;sendgrid-subscription-widget&#34; data-token=&#34;s%2FyRM37csnDZE2YNQgMgA%2FrRJMnvJB6PyYYUOnu3QGxoLuVzko05dg04VrpUhqXh&#34;
    &lt;form&gt;
        &lt;div class=&#34;response&#34;&gt;&lt;/div&gt;
        &lt;label&gt;
        &lt;br /&gt;
            &lt;span&gt;interested in using this, enter email below!&lt;/span&gt;
            &lt;br /&gt;
            &lt;br /&gt;
            &lt;input type=&#34;email&#34; name=&#34;email&#34; placeholder=&#34;enter email&#34; /&gt;
        &lt;/label&gt;
        &lt;input type=&#34;submit&#34; value=&#34;submit :)&#34; /&gt;
    &lt;/form&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>about neural niche</title>
      <link>http://neuralniche.com/about/</link>
      <pubDate>Wed, 19 Aug 2015 12:02:02 -0700</pubDate>
      
      <guid>http://neuralniche.com/about/</guid>
      <description>

&lt;h2 id=&#34;about-neural-niche:6083a88ee3411b0d17ce02d738f69d47&#34;&gt;about neural niche:&lt;/h2&gt;

&lt;p&gt;ideas, plans, and guides to use generative neural networks and machine learning in way&amp;rsquo;s that are both novel and useful&lt;/p&gt;

&lt;h2 id=&#34;contact-me:6083a88ee3411b0d17ce02d738f69d47&#34;&gt;contact me:&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;mailto:graham.annett@gmail.com&#34;&gt;graham&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>